# DeepMath: 开源数学大模型项目

## 项目简介
DeepMath 是一个由同济大学数学科学学院 DeepMath 团队发起的开源项目，旨在训练一个能够达到数学专业博士生水平的数学大模型。项目不仅致力于提升模型的数学推理能力，还探索大模型是否具备数学创造能力，以及其在前沿数学研究中的潜在应用。

## 项目结构

### 一. 数据组
**参与要求：**
- 数学专业背景
- 提供真实姓名与学校（发布成果时可自愿选择是否公开姓名）

**研究内容：**
1. **数据规则提炼**：
   - 提炼数学各分支的数据规则，例如计算题的“套路”、证明题的证明模式等。
   - 基于这些规则编写 Python 模板，批量生成数据。
2. **数据增强与合成**：
   - 研究并实现其他数据增强或合成数学数据的方法。
3. **强化学习规则奖励函数**：
   - 构建用于强化学习的规则奖励函数，编写多样化的数学规则。
4. **非数学专业贡献**：
   - 非数学专业背景的参与者可以提供自己不会的数学题目或遇到的学习困难，要求提供非常详细的描述。

### 二. 模型组
**参与要求：**
- 具有良好的机器学习基础
- 具有大模型训练经验者优先

**研究内容：**
1. **算法研究**：
   - 贡献必要的代码。
2. **数据配比优化**：
   - 研究如何更好地设置数据配比，是否需要形式化数学数据。
3. **训练方法优化**：
   - 研究如何更好地优化已有训练方法，选择更合适的训练参数。
4. **强化学习方法**：
   - 研究强化学习是否需要树搜索，是否需要过程奖励函数。
5. **模型生成引导**：
   - 研究如何在强化学习过程中更好地引导模型生成，编写合适的数学提示词。
6. **推理时计算**：
   - 研究推理时的计算方法。
7. **其他**：
   - 探索其他相关研究方向。

### 三. 测评与应用组
**参与要求：**
- 数学专业背景

**研究内容：**
1. **自动化测评**：
   - 协助进行自动化测评。
2. **人工测评**：
   - 由数学专业学生完成，项目训练的模型测评网站为 [www.deepmath.cn](http://www.deepmath.cn)，其他模型可在相应模型方官网进行测评。
3. **评测集构建**：
   - 构建新的评测集，涵盖数学各分支。
4. **前沿探索**：
   - 探索大模型是否具有数学创造能力，例如构造反例的能力。
   - 结合一两个数学难题进行人机协作研究，探索大模型在前沿数学研究中的应用。

## 第一项工作：DeepMath-Creative评测集

### 论文标题

**DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of Large Language Models**

### 摘要概述

为了进一步提升大模型的数学能力，DeepMath团队发起了一个开源计划，旨在训练一个开源数学大模型，探索大模型的数学创造能力。本文是该开源计划的第一个工作。目前大语言模型在数学领域的发展主要聚焦于推理能力，已有丰富的评测集用于测试其初等或本科水平的数学推理能力。然而，目前鲜有工作研究大模型的数学创造能力，并且用于评测大模型数学创造能力的数据稀缺。本文研究了大模型的数学创造能力的衡量标准，并构建了一个高质量评测数据集**DeepMath-Creative**，涵盖代数、几何、分析等分支的构造性问题，系统评估了当前主流大语言模型在数学问题上的创造性能力。实验结果表明，即使在相当宽松的评分标准下：强调核心解题步骤，忽略次要错误，如逻辑小漏洞、论证不完整或表述冗余等细节误差。表现最好的模型 O3 Mini 在本科层级的构造性问题上准确率也仅为 70%。在更复杂的问题上，模型性能急剧下降，对于开放问题，模型甚至无法提供有效建议。这一结果表明，尽管当前大模型在熟悉且难度较低的问题中表现出一定的构造能力，但其解题过程多依赖于记忆模式的重组，而非源于真正的创造性理解或新颖的结构性构造。

### 数据集位置

本论文所使用的 **DeepMath-Creative** 数据集已开源，位于本项目的 [`DeepMath/DeepMath-Creative/`](./DeepMath/DeepMath-Creative/) 文件夹中，包含以下内容：

- 创新评测集
- 开放问题集

## 联系方式
如有任何问题或合作意向，请联系项目团队，邮箱：[xychen100@tongji.edu.cn]。

## 项目贡献
欢迎所有对数学和机器学习感兴趣的朋友们加入我们，共同推动 DeepMath 项目的发展。
