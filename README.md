# DeepMath: 开源数学大模型项目

## 项目简介
DeepMath 是一个由同济大学数学科学学院 DeepMath 团队发起的开源项目，旨在训练一个能够达到数学专业博士生水平的数学大模型。项目不仅致力于提升模型的数学推理能力，还探索大模型是否具备数学创造能力，以及其在前沿数学研究中的潜在应用。

## 项目结构

### 一. 数据组
**参与要求：**
- 数学专业背景
- 提供真实姓名与学校（发布成果时可自愿选择是否公开姓名）

**研究内容：**
1. **数据规则提炼**：
   - 提炼数学各分支的数据规则，例如计算题的“套路”、证明题的证明模式等。
   - 基于这些规则编写 Python 模板，批量生成数据。
2. **数据增强与合成**：
   - 研究并实现其他数据增强或合成数学数据的方法。
3. **强化学习规则奖励函数**：
   - 构建用于强化学习的规则奖励函数，编写多样化的数学规则。
4. **非数学专业贡献**：
   - 非数学专业背景的参与者可以提供自己不会的数学题目或遇到的学习困难，要求提供非常详细的描述。

### 二. 模型组
**参与要求：**
- 具有良好的机器学习基础
- 具有大模型训练经验者优先

**研究内容：**
1. **算法研究**：
   - 贡献必要的代码。
2. **数据配比优化**：
   - 研究如何更好地设置数据配比，是否需要形式化数学数据。
3. **训练方法优化**：
   - 研究如何更好地优化已有训练方法，选择更合适的训练参数。
4. **强化学习方法**：
   - 研究强化学习是否需要树搜索，是否需要过程奖励函数。
5. **模型生成引导**：
   - 研究如何在强化学习过程中更好地引导模型生成，编写合适的数学提示词。
6. **推理时计算**：
   - 研究推理时的计算方法。
7. **其他**：
   - 探索其他相关研究方向。

### 三. 测评与应用组
**参与要求：**
- 数学专业背景

**研究内容：**
1. **自动化测评**：
   - 协助进行自动化测评。
2. **人工测评**：
   - 由数学专业学生完成，项目训练的模型测评网站为 [www.deepmath.cn](http://www.deepmath.cn)，其他模型可在相应模型方官网进行测评。
3. **评测集构建**：
   - 构建新的评测集，涵盖数学各分支。
4. **前沿探索**：
   - 探索大模型是否具有数学创造能力，例如构造反例的能力。
   - 结合一两个数学难题进行人机协作研究，探索大模型在前沿数学研究中的应用。

## 第一项工作：DeepMath-Creative评测集

### 论文标题

**DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of Large Language Models**

### 摘要概述

为推动大语言模型（LLMs）在数学能力上的进步，DeepMath 团队发起了一个开源计划，旨在开发面向数学的开源大模型，并系统性地评估其数学创造力。本论文是该计划的首项工作。
当前数学大模型的发展大多集中于推理能力，主要通过针对基础到本科阶段的任务进行评估，而其在“创造性数学构造”方面的表现与评测则相对缺乏关注。
为弥补这一空白，我们提出了数学创造力的评估标准，并构建了高质量评测集 **DeepMath-Creative**，涵盖代数、几何、数学分析等多个领域的创新构造类问题。我们使用该评测集对主流大模型的数学创造力进行了系统评估。
即使在宽松的评分标准下（强调核心解题步骤，忽略次要错误，如推理缺口、不完整解释或冗余表述），表现最好的模型 O3 Mini 也仅在本科基础任务上达到约 70% 的准确率。面对更复杂的问题，模型在提供有效策略方面表现不佳，难以解决开放问题。
这些结果表明，当前大模型虽具备一定的构造能力，但主要限于熟悉场景，其表现更多来自对记忆模式的重组，而非真正具备创造性思维或新颖构造能力。

### 数据集位置

本论文所使用的 **DeepMath-Creative** 数据集已开源，位于本项目的 [`DeepMath/DeepMath-Creative/`](./DeepMath/DeepMath-Creative/) 文件夹中，包含以下内容：

- 基础评测集
- 创新评测集
- 开放问题集

## 联系方式
如有任何问题或合作意向，请联系项目团队，邮箱：[xychen100@tongji.edu.cn]。

## 项目贡献
欢迎所有对数学和机器学习感兴趣的朋友们加入我们，共同推动 DeepMath 项目的发展。
